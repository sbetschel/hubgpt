# tools/search_web.py

from duckduckgo_search import DDGS
from datetime import datetime

def execute(query, llm_client=None, file_type=None):
    print("search web tool called")
    """
    Perform a web search for the given query and process the results using an LLM to pick the top 5 most useful results.

    Parameters:
    - query (str): The search query to find relevant web results.
    - llm_client: An LLM client for additional processing of the search results.
    - file_type (optional): The type of file to search for (e.g., pdf, docx, pptx).

    Returns:
    - str: A curated subset of the top search results, processed by the LLM.
    """
    print("Starting web search function")

    # Initialize DuckDuckGo search
    ddgs = DDGS()
    current_date = datetime.now().strftime("%Y-%m")

    # Modify query to include file type if specified
    search_query = f"{query} {current_date}"
    if file_type:
        search_query += f" filetype:{file_type}"
        print(f"Searching for file type: {file_type}")

    print(f"Performing search for query: '{search_query}'")
    
    try:
        results = ddgs.text(search_query, max_results=10)
    except Exception as e:
        print(f"Error during DuckDuckGo search: {e}")
        return "An error occurred during the web search step."

    # Aggregate search results into a JSON-like structure for easier processing
    search_results = []
    if results:
        print("Search results obtained successfully")
        for result in results:
            search_results.append({
                "title": result.get('title', 'No title'),
                "url": result.get('href', 'No URL'),
                "description": result.get('body', 'No description')
            })
        # Convert results to string for display and potential LLM processing
        formatted_results = "\n".join(
            f"Title: {res['title']}\nURL: {res['url']}\nDescription: {res['description']}\n"
            for res in search_results
        ).strip()
        print(f"Formatted search results from DDG: {formatted_results}")
    else:
        print(f"No results found for query: {query}")
        return f"Could not find results for {query}."

    # Prepare the LLM messages array for processing search results
    messages = [
        {"role": "system", "content": "You are a gifted search analyst. You are able to assess the likely usefulness of a given web page by analysing the search result for that web page. You will be given a user query and a json object containing search results for that query (incl title, url, description). You must reply in json in this format [\r\n    {\r\n        \"title\": \"title of the webpage\",\r\n        \"url\": \"url of the webpage\",\r\n        \"description\": \"search result description of the webpage\",\r\n        \"rank\": \"rank the search results by how likely you think they are to contain relevant content to answer the user query. eg if you return 5 results, then you should rank them 1 to 5 where 1 is the highest rank (ie most likely to have content that will answer the question)\",\r\n        \"rationale\": \"your short rationale for why you have given it that rank\"\r\n    }\r\n] "},
        {
            "role": "user",
            "content": f"The query is:\n\n {query} \n\nAnalyse the search results below then return the 5 results you have selected and ranked.\n\nSEARCH RESULTS:\n\n{formatted_results}"
        }
    ]

    print("Sending search results to LLM for analysis")

    # Send to LLM for processing
    try:
        response = llm_client.chat.completions.create(
            model="google/gemini-flash-1.5-8b",
            messages=messages,
            max_tokens=2000,
            temperature=1
        )
        print("LLM response received successfully")
        
        # Extract and return the LLM's curated response
        curated_results = response.choices[0].message.content.strip()
        print(f"Curated results generated by LLM: {curated_results}")
        return curated_results
    except Exception as e:
        print(f"Error during LLM processing: {e}")
        return "An error occurred while processing the LLM response."

# Tool metadata
TOOL_METADATA = {
    "type": "function",
    "function": {
        "name": "search_web",
        "description": "Search the web for the given query and return results.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "The search query to execute, based on the user's message. Determine the intent and rephrase to get the best possible results."
                },
                "file_type":{
                    "type": "string",
                    "description": "The file type to search for. Specify this if the user is looking for a particular file format (e.g., pdf, docx, pptx).",
                    "enum": ["pdf", "docx", "pptx", "xls", "html"]
                }
            },
            "required": ["query"]
        }
    }
}
